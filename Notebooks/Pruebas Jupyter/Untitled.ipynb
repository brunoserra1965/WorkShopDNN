{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer Ejemplo con KERAS\n",
    "\n",
    "Cargamos el conjunto de datos MNIST y lo dividimos en conjuntos de entrenamiento y prueba, con X_train y X_test que contiene las imágenes de entrenamiento y prueba, y_train e y_test contiene el valor real de los dígitos representados en las imágenes. En el conjunto de datos MNIST, se usan 60.000 imágenes para entrenamiento y 10.000 para pruebas/validación.\n",
    "\n",
    "Primero importamos las librerias a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos una de las imágenes con la función plt.imshow y comprobamos su tamaño con la función .shape para comprender cómo se vera el conjunto de datos. \n",
    "Como se ve, todas las imágenes MNIST tienen un tamaño uniforme de 28 x 28 píxeles y contienen dígitos escritos a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[10000])\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos la forma de los dos conjuntos de imágenes X_train y X_test, según la forma esperada por el modelo CNN. \n",
    "La función reshape de Keras toma cuatro argumentos: \n",
    "    - Número de imágenes de entrenamiento.\n",
    "    - Tamaño de píxel (m,n) .\n",
    "    - Profundidad de imagen: usamos 1 para indicar una imagen en escala de grises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000,28,28,1)\n",
    "X_test = X_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, generamos un hot encoding de la variable de destino: creamos una columna para cada categoría de clasificación, donde cada columna contiene 0 o 1 que indican si la imagen actual pertenece o no a esa categoría. \n",
    "Debido a que estamos clasificando dígitos, habrá 10 columnas para los dígitos del 0 al 9, y de acuerdo con la decisión de clasificación, una de las columnas tendrá un 1 (por ejemplo, la columna para el dígito 3) y el resto será 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un modelo, utilizando la clase Sequential , que nos permite construir un modelo agregando una capa a la vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos capas de modelo: las dos primeras capas son Conv2D que son capas convolucionales bidimensionales. Estas son capas de convolución que tratan con las imágenes de entrada, que se ven como matrices bidimensionales. La función Conv2D toma cuatro parámetros:\n",
    "\n",
    "    - Número de neuronas en cada capa. Usaremos 64 para la primera capa convolucional y 32 para la segunda.\n",
    "    - kernel_size: Define el tamaño del filtro: es el área en píxeles cuadrados que el modelo usará para \"escanear\" la imagen. El tamaño de kernel de 3 significa que el modelo utilizara un cuadrado de 3 × 3 píxeles a la vez.\n",
    "    - activación: Es el tipo de función de activación que usamos después de cada capa convolucional. Para CNN, la función de activación típica utilizada es ReLu.\n",
    "    - input_shape: Es el tamaño de píxel de las imágenes y la profundidad de la imagen, nuevamente configurando 1 para escala de grises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregue una capa 'Flatten', que toma la salida de las dos capas de convolución y la convierte en un formato que puede ser utilizado por la capa neural final, totalmente conectada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregue la capa final de la red neuronal del tipo 'Dense', una capa neural totalmente conectada que generará la predicción final. La función Densa toma dos argumentos:\n",
    "\n",
    "    - Número de nodos de salida: 10 en nuestro caso porque necesitamos generar predicciones para dígitos entre 0-9.\n",
    "    - Tipo de función de activación para la capa de salida. Usamos softmax que es la función de activación típica utilizada para las capas de salida de la red neural. Softmax toma la salida de la capa densa y la convierte en probabilidades significativas para cada uno de los dígitos, que suman 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el modelo. La funcion 'Compile' toma tres parámetros:\n",
    "    - optimizer: Controla la tasa de aprendizaje, que define qué tan rápido se calculan los pesos óptimos para el modelo. Utilizaremos el optimizador de velocidad de aprendizaje llamado 'adam'.\n",
    "    - loss: Define la función de pérdida, que mide qué tan lejos está la predicción del modelo del valor real de los dígitos para las imágenes. Utilizaremos 'categorical_crossentropy', una función de pérdida adecuada para problemas de clasificación.\n",
    "    - metrics: Define cómo evaluamos el éxito del modelo. Utilizaremos la métrica de 'precisión' para calcular un puntaje de precisión en el conjunto de imágenes de prueba/validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenando el modelo, usando la función fit consta de cuatro parámetros:\n",
    "    - datos de entrenamiento (train_X)  \n",
    "    - datos de destino (train_y)\n",
    "    - datos de validación\n",
    "    - número de épocas (número de veces que se ejecutará el proceso de propagación hacia atrás en las imágenes de entrenamiento) lo configuraremos en 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.2188 - accuracy: 0.9507 - val_loss: 0.1054 - val_accuracy: 0.9709\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0679 - accuracy: 0.9790 - val_loss: 0.0869 - val_accuracy: 0.9761\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.0456 - accuracy: 0.9859 - val_loss: 0.1029 - val_accuracy: 0.9710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17077260148>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver arriba, después de tres épocas, la precisión en el conjunto de validación es de 97.61%. La CNN funciona bien.\n",
    "\n",
    "Ahora que el modelo está funcionando, podemos generar predicciones reales utilizando la función _PREDICT_. \n",
    "La función devuelve una matriz de probabilidades para cada uno de los 10 resultados posibles (dígitos entre 0-9), con la suma de probabilidades para cada imagen igual a 1. \n",
    "Podemos ingresar datos nuevos y desconocidos a la función de predicción para obtener la predicción de nuestro modelo. Por ahora, vamos a hacer una predicción para las primeras cuatro imágenes en el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_nums(predict):\n",
    "    for elem in predict:\n",
    "        print(np.where(elem == np.amax(elem))[0][0])\n",
    "        \n",
    "def comparate_prediction(predict, realValues):\n",
    "    for index in range(0, len(predict)):\n",
    "        print(f\"Model predict: {np.where(predict[index] == np.amax(predict[index]))[0][0]} - Real num: {np.where(realValues[index] == np.amax(realValues[index]))[0][0]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(X_test[:4])\n",
    "\n",
    "predictions_nums(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida mostrará probabilidades para los dígitos 0-9, para cada una de las 4 imágenes. El modelo predice 7, 2, 1 y 0 para las primeras cuatro imágenes.\n",
    "\n",
    "Comparamos esto con los resultados reales de las primeras 4 imágenes en el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predict: 7 - Real num: 7\n",
      "Model predict: 2 - Real num: 2\n",
      "Model predict: 1 - Real num: 1\n",
      "Model predict: 0 - Real num: 0\n"
     ]
    }
   ],
   "source": [
    "comparate_prediction(predict, y_test[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida muestra que los valores reales para las primeras cuatro imágenes también es 7, 2,1 y 0, por lo tanto, el modelo hizo una predicción precisa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

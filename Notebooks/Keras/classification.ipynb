{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FE7KNzPPVrVV"
   },
   "source": [
    "# Clasificación de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gN7G9GFmVrVY"
   },
   "source": [
    "En este notebook vamos a desarrollar un módelo para clasificar gatos o perros a partir de imágenes. Para esto utilizaremos un clasificador de imágenes usando un modelo `tf.keras.Sequential` y para la carga datos usaremos `tf.keras.preprocessing.image.ImageDataGenerator`.\n",
    "\n",
    "Seguiremos el siguiente orden de tareas:\n",
    "\n",
    "1. Examinar y entender los datos\n",
    "2. Construir un pipeline de entrada\n",
    "3. Construir un modelo.\n",
    "4. Entrenar el modelo\n",
    "5. Testear el modelo\n",
    "6. Mejorar el modelo aplicando técnicas y volver a entranar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repaso sobre elementos a utilizar para este ejemplo \n",
    "\n",
    "Keras es muy bueno para la creación rápida de prototipos. En poco tiempo se puede construir un modelo que logre resultados muy buenos.\n",
    "\n",
    "### 1 - Para cargar los datos:\n",
    "Como se mencionó vamos a utilizar `tf.keras.preprocessing.image.ImageDataGenerator` que se debe inicializar para cada tipo de datos que tengamos (train, dev, etc).\n",
    "Un ej de como hacerlo es: `gen = ImageDataGenerator(rescale=1./255)`\n",
    "\n",
    "Como en nuestro caso vamos a leer los archivos desde varias carpetas, podemos utilizar:\n",
    "```\n",
    "gen.flow_from_directory(batch_size=batch_size,\n",
    "                    directory=train_dir,\n",
    "                    shuffle=True,\n",
    "                    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                    class_mode='binary')\n",
    "```\n",
    "\n",
    "### 2 - Definir un modelo:\n",
    "\n",
    "Como utilizaremos modelos secuenciales, en cada etapa se le aplica una operacion a la vez a la CNN, podemos usar:\n",
    "```\n",
    "model = Sequential([\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "])\n",
    "```\n",
    "Dentro de los parentesis rectos se pueden concatenar tantas operaciones como se quiera, siendo algunos ejemplos:\n",
    " * Conv2D(filters=16, kernel_size=(7, 7), strides=(1, 1), padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3))\n",
    " * BatchNormalization(axis=3)\n",
    " * MaxPooling2D((2,2))\n",
    " * Flatten()\n",
    " * Dense(units=512, activation='relu')\n",
    "```\n",
    "model = Sequential([\n",
    "    Conv2D(filters=16, kernel_size=(7, 7), strides=(1, 1), padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    BatchNormalization(axis=3),\n",
    "    ...\n",
    "    ...\n",
    "])\n",
    "```\n",
    "### 3 - Compilar el modelo\n",
    "```\n",
    "model.compile(optimizer= , nombre_optimizador\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), función de pérdida\n",
    "              metrics=[]) arreglo con todas las metricas a sacar\n",
    "```\n",
    "\n",
    "### 4 - Entrenar el modelo\n",
    "Para esto la clase ImageDataGenerator tiene el método fit en donde algunos parámetros a configurar son:\n",
    "```\n",
    "model.fit(\n",
    "    train_data_gen,  conjunto de entrenamiento\n",
    "    steps_per_epoch= ,  # de pasos en cada epochs\n",
    "    epochs= ,  # de epochs\n",
    "    validation_data= , conjunto de validacion\n",
    "    validation_steps= \n",
    ")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zF9uvbXNVrVY"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VddxeYBEVrVZ"
   },
   "source": [
    "* El paquete `os` se usa para leer archivos y estructura de directorios\n",
    "* `NumPy` se usa para realizar las operaciones de matriz requeridas\n",
    "* `matplotlib.pyplot` para gráficar y mostrar imágenes en los datos de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jlchl4x2VrVg"
   },
   "source": [
    "Importar Tensorflow y las clases de Keras necesarias para construir nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1WtoaOHVrVh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZZI6lNkVrVm"
   },
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Giv0wMQzVrVw"
   },
   "source": [
    "El conjunto de datos tiene la siguiente estructura:\n",
    "<pre>\n",
    "<b>cats_and_dogs_filtered</b>\n",
    "|__ <b>train</b>\n",
    "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ....]\n",
    "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
    "|__ <b>validation</b>\n",
    "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ....]\n",
    "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpmywIlsVrVx"
   },
   "source": [
    "Asignar las variables con la ruta de archivo adecuada para el conjunto de capacitación y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sRucI3QqVrVy"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join('datasets', 'train')\n",
    "validation_dir = os.path.join('datasets', 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Utv3nryxVrV0"
   },
   "outputs": [],
   "source": [
    "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZdrHHTy2VrV3"
   },
   "source": [
    "## Estudiando el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vc4u8e9hVrV4"
   },
   "outputs": [],
   "source": [
    "num_cats_tr = len(os.listdir(train_cats_dir))\n",
    "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
    "\n",
    "num_cats_val = len(os.listdir(validation_cats_dir))\n",
    "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
    "\n",
    "total_train = num_cats_tr + num_dogs_tr\n",
    "total_val = num_cats_val + num_dogs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4GGzGt0VrV7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('total training cat images:', num_cats_tr)\n",
    "print('total training dog images:', num_dogs_tr)\n",
    "\n",
    "print('total validation cat images:', num_cats_val)\n",
    "print('total validation dog images:', num_dogs_val)\n",
    "print(\"--\")\n",
    "print(\"Total training images:\", total_train)\n",
    "print(\"Total validation images:\", total_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Lp-0ejxOtP1"
   },
   "source": [
    "Configurar las variables que se utilizaron para el mini-batch, las épocas y las dimensiones de las imagenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NqNselLVrWA"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Jfk6aSAVrWD"
   },
   "source": [
    "Formatear las imágenes en tensores de punto flotante preprocesados ​​adecuadamente antes de alimentar a la red:\n",
    "\n",
    "1. Leer imágenes del disco.\n",
    "2. Docodificar el contenido de estas imágenes y convertirlo al formato de cuadrícula adecuado según su contenido RGB.\n",
    "3. Convertirlos en tensores de punto flotante.\n",
    "4. Cambiar la escala de los tensores de valores entre 0 y 255 a valores entre 0 y 1, ya que las redes neuronales prefieren tratar con valores de entrada pequeños.\n",
    "\n",
    "Todas estas tareas se pueden realizar con la clase `ImageDataGenerator` proporcionada por `tf.keras`. Puede leer imágenes del disco y preprocesarlas en tensores adecuados. También establecerá generadores que conviertan estas imágenes en batch de tensores, lo que es útil para entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "syDdF_LWVrWE"
   },
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLciCR_FVrWH"
   },
   "source": [
    "Después de definir los generadores para las imágenes de entrenamiento y validación, el método `flow_from_directory` carga las imágenes desde el disco, aplica el cambio de escala y cambia el tamaño de las imágenes a las dimensiones requeridas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pw94ajOOVrWI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode='binary',\n",
    "                                                           color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2oUoKUzRVrWM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='binary',\n",
    "                                                              color_mode='rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hyexPJ8CVrWP"
   },
   "source": [
    "### Visualizar ejemplos de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "60CnhEL4VrWQ"
   },
   "source": [
    "Visualizar las imágenes de entrenamiento extrayendo un lote de imágenes del generador de entrenamiento, que son 32 imágenes en este ejemplo, luego graficar cinco de ellas con `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3f0Z7NZgVrWQ"
   },
   "outputs": [],
   "source": [
    "sample_training_images, _ = next(train_data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49weMt5YVrWT"
   },
   "source": [
    "La función `next` devuelve un batch del conjunto de datos. El valor de retorno de la función `next` está en forma de `(x_train, y_train)` donde x_train son las características de entrenamiento y y_train, sus etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMt2RES_VrWU"
   },
   "outputs": [],
   "source": [
    "# This function will plot images in the form of a grid with 1 row and 8 columns where images are placed in each column.\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 8, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_VVg_gEVrWW"
   },
   "outputs": [],
   "source": [
    "plotImages(sample_training_images[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ver algunos datos mas del dataset\n",
    "print(\"Labels conjunto entrenamiento:\", train_data_gen.classes)\n",
    "print(\"Indices de las clases:\", train_data_gen.class_indices)\n",
    "print(\"Formato de las imágenes:\", train_data_gen.image_shape)\n",
    "print(\"Cantidad de clases:\", train_data_gen.num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5Ej-HLGVrWZ"
   },
   "source": [
    "## Crear el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wEgW4i18VrWZ"
   },
   "source": [
    "El modelo consta de tres bloques de convolución con una capa de agrupación máxima en cada uno de ellos. Hay una capa totalmente conectada con 512 unidades encima que se activa mediante una función de activación `relu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F15-uwLPVrWa"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', \n",
    "           input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PI5cdkMQVrWc"
   },
   "source": [
    "### Compilar el modelo\n",
    "\n",
    "Elegir el optimizador * ADAM * y la función de pérdida * BinaryCrossentropy *. Para ver la precisión de la capacitación y la validación para cada época de capacitación, pase el argumento `metrics`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Mg7_TXOVrWd"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YmQZ3TAVrWg"
   },
   "source": [
    "### Resumen del modelo\n",
    "\n",
    "Vea todas las capas de la red utilizando el método `summary` del modelo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vtny8hmBVrWh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N06iqE8VVrWj"
   },
   "source": [
    "### Entrenar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oub9RtoFVrWk"
   },
   "source": [
    "Use el método `fit` de la clase `ImageDataGenerator` para entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSF2HqhDVrWk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_gen.reset()\n",
    "val_data_gen.reset()\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=total_train // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=total_val // batch_size    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojJNteAGVrWo"
   },
   "source": [
    "### Visualizar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6oA77ADVrWp"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kDnr50l2VrWu"
   },
   "source": [
    "Como puede ver en las gráficas, la precisión del entrenamiento y la precisión de la validación están separadas por un amplio margen y el modelo ha logrado solo alrededor del ** 70% ** de precisión en el conjunto de validación.\n",
    "\n",
    "Analizaremos brevemente que salio mal y que se podría llegar a cambiar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rLO7yhLlVrWu"
   },
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNyx3Lp4VrWv"
   },
   "source": [
    "En las gráficas anteriores, la precisión del entrenamiento aumenta linealmente con el tiempo, mientras que la precisión de la validación se detiene alrededor del 70% en el proceso de entrenamiento. Además, la diferencia en la precisión entre el entrenamiento y la precisión de la validación es notable, una señal de * overfitting *.\n",
    "\n",
    "Cuando hay un pequeño número de ejemplos de entrenamiento, el modelo a veces aprende de los ruidos o detalles no deseados de los ejemplos de entrenamiento, hasta el punto de que impacta negativamente el desempeño del modelo en nuevos ejemplos. Este fenómeno se conoce como overfitting. Significa que el modelo tendrá dificultades para generalizar en un nuevo conjunto de datos.\n",
    "\n",
    "Hay múltiples formas de luchar contra el sobreajuste en el proceso de entrenamiento. En este caso usaremos * aumento de datos *."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOoVpxFwVrWy"
   },
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wn_QLciWVrWy"
   },
   "source": [
    "El overfitting generalmente ocurre cuando hay un pequeño número de ejemplos de entrenamiento. Una forma de solucionar este problema es aumentar el conjunto de datos para que tenga una cantidad suficiente de ejemplos de entrenamiento. El aumento de datos adopta el enfoque de generar más datos de entrenamiento a partir de muestras de entrenamiento existentes al aumentar las muestras usando transformaciones aleatorias que producen imágenes de aspecto creíble. El objetivo es que el modelo nunca verá exactamente la misma imagen dos veces durante el entrenamiento. Esto ayuda a exponer el modelo a más aspectos de los datos y a generalizar mejor.\n",
    "\n",
    "Esto se puede implementar en `tf.keras` usando la clase `ImageDataGenerator`. Las transformaciones se aplican al conjunto de datos y durante el entrenamiento serán aplicados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2uJ1G030VrWz"
   },
   "source": [
    "### Aumentar y visualizar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvX7hHlgVrW0"
   },
   "source": [
    "Comenzaremos invirtiendo horizontalmente al conjunto de datos en forma aleatoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rlVj6VqaVrW0"
   },
   "source": [
    "### Invertir imágenes horizontalmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xcdvx4TVVrW1"
   },
   "source": [
    "Pasar `horizontal_flip` como argumento a la clase `ImageDataGenerator` y configurarlo en `True` para aplicar este aumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bi1_vHyBVrW2"
   },
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvwqmefgVrW3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                               directory=train_dir,\n",
    "                                               shuffle=True,\n",
    "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJpRSxJ-VrW7"
   },
   "source": [
    "Con el siguiente comando podemos ver como de forma aleatoria se invierte la imágen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RrKGd_jjVrW7"
   },
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvBZoQ9xVrW9"
   },
   "outputs": [],
   "source": [
    "# Re-use the same custom plotting function defined and used\n",
    "# above to visualize the training images\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i7n9xcqCVrXB"
   },
   "source": [
    "### Rotación aleatoria de la imágen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXnwkzFuVrXB"
   },
   "source": [
    "Ahora vamos a ver otro tipo de aumento diferente llamado rotación y aplicaremos 45 grados de rotación al azar a los ejemplos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zip35pDVrXB"
   },
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVoWh4OIVrXD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                               directory=train_dir,\n",
    "                                               shuffle=True,\n",
    "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "augmented_images = [train_data_gen[0][0][0] for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmBx8NhrVrXK"
   },
   "outputs": [],
   "source": [
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FOqGPL76VrXM"
   },
   "source": [
    "### Aplicar aumento de zoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NvqXaD8BVrXN"
   },
   "source": [
    "Aplicaremos un aumento de zoom al conjunto de datos para ampliar las imágenes hasta un 50% al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGNKLa_YVrXR"
   },
   "outputs": [],
   "source": [
    "# zoom_range from 0 - 1 where 1 = 100%.\n",
    "image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VOvTs32FVrXU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                               directory=train_dir,\n",
    "                                               shuffle=True,\n",
    "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "augmented_images = [train_data_gen[0][0][0] for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-KQWw8IZVrXZ"
   },
   "outputs": [],
   "source": [
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "usS13KCNVrXd"
   },
   "source": [
    "### Aplicar todas las modificaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OC8fIsalVrXd"
   },
   "source": [
    "Aplicar todos los aumentos anteriores. En este caso se aplica, reescalado, rotación de 45 grados, desplazamiento de ancho, desplazamiento de altura, giro horizontal y aumento de zoom a las imágenes de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gnr2xujaVrXe"
   },
   "outputs": [],
   "source": [
    "image_gen_train = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=45,\n",
    "                    width_shift_range=.15,\n",
    "                    height_shift_range=.15,\n",
    "                    horizontal_flip=True,\n",
    "                    zoom_range=0.5\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0Efxy7EVrXh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=train_dir,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AW-pV5awVrXl"
   },
   "source": [
    "Podemos ver cómo se vería una sola imagen ocho veces diferentes al pasar estos aumentos al azar al conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2m68eMhVrXm"
   },
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(8)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J8cUd7FXVrXq"
   },
   "source": [
    "### Crear generador de datos de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a99fDBt7VrXr"
   },
   "source": [
    "En general, solo se aplica el aumento de datos a los ejemplos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54x0aNbKVrXr"
   },
   "outputs": [],
   "source": [
    "image_gen_val = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1PCHKzI8VrXv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
    "                                                 directory=validation_dir,\n",
    "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Utilizar el modelo en nuevos datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = tf.keras.preprocessing.image.load_img(\n",
    "    \"C:/Work/Itau/WorkShopDNN/WorkShopDNN/Notebooks/Keras/datasets/test/cats/IMG-1571.jpg\",\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH)\n",
    ")\n",
    "\n",
    "\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) / 255\n",
    "print(img_array.shape)\n",
    "pred = model.predict(img_array, verbose=1)     \n",
    "print(pred[0])                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "# custom function\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "# define vectorized sigmoid\n",
    "sigmoid_v = np.vectorize(sigmoid)\n",
    "\n",
    "test_dir = os.path.join('datasets', 'test')\n",
    "image_gen_test = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = image_gen_test.flow_from_directory(batch_size=batch_size,\n",
    "                                                 directory=test_dir,\n",
    "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                 class_mode='binary',\n",
    "                                                 shuffle=False)\n",
    "test_data_gen.reset()\n",
    "pred = model.predict(test_data_gen, verbose=1)  \n",
    "print(np.round(sigmoid_v(pred), decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}